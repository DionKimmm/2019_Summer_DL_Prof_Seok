{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190801_Fashion-MNIST_0.94_accuracy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DionKimmm/2019_Summer_DL_Prof_Seok/blob/master/190801_Fashion_MNIST_0_94_accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVfXx79Xcumj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e477c832-828c-4aa9-884f-1307e9f8ae7a"
      },
      "source": [
        "!unzip fashion-mnist.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open fashion-mnist.zip, fashion-mnist.zip.zip or fashion-mnist.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IviX5I-_dtbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27f485be-5a29-4a50-cce7-3abb7bdda7b4"
      },
      "source": [
        "!rm fashion-mnist.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'fashion-mnist.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYQWReTMjVVZ",
        "colab_type": "text"
      },
      "source": [
        "# 참고 블로그"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjLQJzn0jWfm",
        "colab_type": "text"
      },
      "source": [
        "https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ddURcobjOug",
        "colab_type": "text"
      },
      "source": [
        "# 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEA6ER4AjP-o",
        "colab_type": "text"
      },
      "source": [
        "* minivggnet.py\n",
        "* (CONV => RELU => BN(배치정규화)) * 2 => POOL\n",
        "* => Fully Connected => Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Pd21uZvjK9q",
        "colab_type": "text"
      },
      "source": [
        "# 단계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjnh4xykjMoe",
        "colab_type": "text"
      },
      "source": [
        "## 필요한 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwdvwoaei_iw",
        "colab_type": "text"
      },
      "source": [
        "### 플롯을 백그라운드에서 실행 가능하게 하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1jNzmani6rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ik1kaNRkh4m",
        "colab_type": "text"
      },
      "source": [
        "* 패션 MNIST 셋은 케라스안에도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2q2K890kPnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3ddf2a1-74bf-4752-d362-3a7ea96474a9"
      },
      "source": [
        "# import the necessary packages\n",
        "from pyimagesearch.minivggnet import MiniVGGNet\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from imutils import build_montages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsvcJz8ckQOz",
        "colab_type": "text"
      },
      "source": [
        "## 학습, 테스트, 레이블 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJiTnJj7kxid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 50\n",
        "INIT_LR = 1e-2\n",
        "BS = 32 # batch size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrdMjT9Tleey",
        "colab_type": "text"
      },
      "source": [
        "케라스 백엔드 이미지 데이터 포맷에 channels_first와 last가 있고, 그에 맞게 re-order 한다고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr_kiqtik6Ns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dcbd5fdb-9ab2-4f90-a3b1-3235fd8eab38"
      },
      "source": [
        "# grab the Fashion MNIST dataset (if this is your first time running\n",
        "# this the dataset will be automatically downloaded)\n",
        "print(\"[INFO] loading Fashion MNIST...\")\n",
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        "print(\"Finish!\")\n",
        "# if we are using \"channels first\" ordering, then reshape the design\n",
        "# matrix such that the matrix is:\n",
        "# \tnum_samples x depth x rows x columns\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
        "\ttestX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
        " # otherwise, we are using \"channels last\" ordering, so the design\n",
        " # matrix shape should be: num_samples x rows x columns x depth\n",
        "else:\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading Fashion MNIST...\n",
            "Finish!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywe9aV9ZlQqX",
        "colab_type": "text"
      },
      "source": [
        "### preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S25nvD1l9xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale data to the range of [0, 1]\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        " \n",
        "# one-hot encode the training and testing labels\n",
        "trainY = np_utils.to_categorical(trainY, 10)\n",
        "testY = np_utils.to_categorical(testY, 10)\n",
        " \n",
        "# initialize the label names\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZLynYKNmQP6",
        "colab_type": "text"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfUo9FYdmeNG",
        "colab_type": "text"
      },
      "source": [
        "* SGD를 옵티마이저로 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2UZx8nUl_dr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0a5e293-0e86-4d5e-a17d-b0439a2038b5"
      },
      "source": [
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
        "model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        " \n",
        "# train the network\n",
        "print(\"[INFO] training model...\")\n",
        "H = model.fit(trainX, trainY,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tbatch_size=BS, epochs=NUM_EPOCHS)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0801 05:32:56.874039 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0801 05:32:56.875864 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0801 05:32:56.877924 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0801 05:32:56.913070 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0801 05:32:56.914053 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0801 05:32:57.628007 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0801 05:32:57.772978 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0801 05:32:57.781141 139851620988800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0801 05:32:58.098064 139851620988800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0801 05:32:58.197196 139851620988800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] training model...\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.5422 - acc: 0.8191 - val_loss: 0.4370 - val_acc: 0.8396\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 0.3477 - acc: 0.8765 - val_loss: 0.3692 - val_acc: 0.8704\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 0.2987 - acc: 0.8931 - val_loss: 0.3126 - val_acc: 0.8857\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 0.2689 - acc: 0.9023 - val_loss: 0.2422 - val_acc: 0.9116\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 17s 275us/step - loss: 0.2531 - acc: 0.9091 - val_loss: 0.2239 - val_acc: 0.9204\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 0.2383 - acc: 0.9143 - val_loss: 0.2155 - val_acc: 0.9204\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 0.2256 - acc: 0.9171 - val_loss: 0.2135 - val_acc: 0.9219\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 0.2161 - acc: 0.9218 - val_loss: 0.2055 - val_acc: 0.9240\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 0.2095 - acc: 0.9247 - val_loss: 0.2068 - val_acc: 0.9231\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 0.2028 - acc: 0.9260 - val_loss: 0.1987 - val_acc: 0.9286\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 0.1955 - acc: 0.9280 - val_loss: 0.2041 - val_acc: 0.9252\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1889 - acc: 0.9312 - val_loss: 0.1961 - val_acc: 0.9284\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 0.1861 - acc: 0.9318 - val_loss: 0.2010 - val_acc: 0.9247\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 0.1816 - acc: 0.9346 - val_loss: 0.1957 - val_acc: 0.9300\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1789 - acc: 0.9354 - val_loss: 0.1875 - val_acc: 0.9333\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1740 - acc: 0.9367 - val_loss: 0.1909 - val_acc: 0.9326\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1690 - acc: 0.9382 - val_loss: 0.1873 - val_acc: 0.9326\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 16s 275us/step - loss: 0.1689 - acc: 0.9377 - val_loss: 0.1855 - val_acc: 0.9323\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1655 - acc: 0.9397 - val_loss: 0.1891 - val_acc: 0.9306\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1638 - acc: 0.9400 - val_loss: 0.1872 - val_acc: 0.9337\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1621 - acc: 0.9411 - val_loss: 0.1834 - val_acc: 0.9322\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1567 - acc: 0.9424 - val_loss: 0.1862 - val_acc: 0.9340\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 0.1567 - acc: 0.9427 - val_loss: 0.1812 - val_acc: 0.9345\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1527 - acc: 0.9441 - val_loss: 0.1821 - val_acc: 0.9355\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1515 - acc: 0.9447 - val_loss: 0.1823 - val_acc: 0.9343\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1500 - acc: 0.9458 - val_loss: 0.1785 - val_acc: 0.9371\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1475 - acc: 0.9453 - val_loss: 0.1812 - val_acc: 0.9366\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1458 - acc: 0.9461 - val_loss: 0.1800 - val_acc: 0.9376\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 0.1462 - acc: 0.9464 - val_loss: 0.1772 - val_acc: 0.9389\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1432 - acc: 0.9469 - val_loss: 0.1771 - val_acc: 0.9386\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1415 - acc: 0.9482 - val_loss: 0.1799 - val_acc: 0.9372\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1405 - acc: 0.9484 - val_loss: 0.1782 - val_acc: 0.9370\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1395 - acc: 0.9486 - val_loss: 0.1767 - val_acc: 0.9391\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1364 - acc: 0.9496 - val_loss: 0.1760 - val_acc: 0.9399\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1347 - acc: 0.9509 - val_loss: 0.1751 - val_acc: 0.9405\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1344 - acc: 0.9506 - val_loss: 0.1781 - val_acc: 0.9390\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 0.1348 - acc: 0.9513 - val_loss: 0.1759 - val_acc: 0.9395\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1316 - acc: 0.9516 - val_loss: 0.1797 - val_acc: 0.9393\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 0.1298 - acc: 0.9533 - val_loss: 0.1777 - val_acc: 0.9396\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1289 - acc: 0.9525 - val_loss: 0.1760 - val_acc: 0.9391\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1278 - acc: 0.9530 - val_loss: 0.1744 - val_acc: 0.9397\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1277 - acc: 0.9528 - val_loss: 0.1779 - val_acc: 0.9395\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 16s 274us/step - loss: 0.1290 - acc: 0.9524 - val_loss: 0.1781 - val_acc: 0.9406\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1240 - acc: 0.9535 - val_loss: 0.1814 - val_acc: 0.9374\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1228 - acc: 0.9544 - val_loss: 0.1779 - val_acc: 0.9413\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 16s 271us/step - loss: 0.1208 - acc: 0.9556 - val_loss: 0.1752 - val_acc: 0.9404\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1226 - acc: 0.9547 - val_loss: 0.1754 - val_acc: 0.9410\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 0.1220 - acc: 0.9550 - val_loss: 0.1750 - val_acc: 0.9407\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 16s 273us/step - loss: 0.1229 - acc: 0.9542 - val_loss: 0.1827 - val_acc: 0.9388\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 16s 272us/step - loss: 0.1198 - acc: 0.9552 - val_loss: 0.1755 - val_acc: 0.9416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9e9kQ6m4qd",
        "colab_type": "text"
      },
      "source": [
        "## 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0F0zD3UnjAQ",
        "colab_type": "text"
      },
      "source": [
        "* 테스트하고 결과값을 이미지로 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2nAMKHOmXyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "2e354ffe-d00a-4d0c-ce20-38eb3063c1e1"
      },
      "source": [
        "# make predictions on the test set\n",
        "preds = model.predict(testX)\n",
        " \n",
        "# show a nicely formatted classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
        "\ttarget_names=labelNames))\n",
        " \n",
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot_epoch_50.png\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         top       0.89      0.91      0.90      1000\n",
            "     trouser       0.99      0.99      0.99      1000\n",
            "    pullover       0.91      0.92      0.92      1000\n",
            "       dress       0.94      0.95      0.94      1000\n",
            "        coat       0.91      0.90      0.91      1000\n",
            "      sandal       0.99      0.99      0.99      1000\n",
            "       shirt       0.84      0.81      0.82      1000\n",
            "     sneaker       0.96      0.98      0.97      1000\n",
            "         bag       0.99      0.99      0.99      1000\n",
            "  ankle boot       0.98      0.97      0.98      1000\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.94      0.94      0.94     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7CUs7L2oUrm",
        "colab_type": "text"
      },
      "source": [
        "## To Visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFJ8d-aupOZD",
        "colab_type": "text"
      },
      "source": [
        "* 를 하려고 했는데 cv2.imshow() is disabled in Colab 이라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxd92Xoxo0B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # initialize our list of output images\n",
        "# images = []\n",
        " \n",
        "# # randomly select a few testing fashion items\n",
        "# for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
        "# \t# classify the clothing\n",
        "# \tprobs = model.predict(testX[np.newaxis, i])\n",
        "# \tprediction = probs.argmax(axis=1)\n",
        "# \tlabel = labelNames[prediction[0]] \n",
        "# \t# extract the image from the testData if using \"channels_first\"\n",
        "# \t# ordering\n",
        "# \tif K.image_data_format() == \"channels_first\":\n",
        "# \t\timage = (testX[i][0] * 255).astype(\"uint8\")\n",
        "# \t# otherwise we are using \"channels_last\" ordering\n",
        "# \telse:\n",
        "# \t\timage = (testX[i] * 255).astype(\"uint8\")\n",
        "# \t# initialize the text label color as green (correct)\n",
        "# \tcolor = (0, 255, 0)\n",
        "# \t# otherwise, the class label prediction is incorrect\n",
        "# \tif prediction[0] != np.argmax(testY[i]):\n",
        "# \t\tcolor = (0, 0, 255)\n",
        "# \t# merge the channels into one image and resize the image from\n",
        "# \t# 28x28 to 96x96 so we can better see it and then draw the\n",
        "# \t# predicted label on the image\n",
        "# \timage = cv2.merge([image] * 3)\n",
        "# \timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "# \tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "# \t\tcolor, 2)\n",
        "# \t# add the image to our list of output images\n",
        "# \timages.append(image)\n",
        "# # construct the montage for the images\n",
        "# montage = build_montages(images, (96, 96), (4, 4))[0]\n",
        " \n",
        "# # show the output montage\n",
        "# cv2.imshow(\"Fashion MNIST\", montage)\n",
        "# cv2.waitKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}